{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "is_front_camera_training = False  # Change it to False if training for down cmaera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# OS PARAMETERS ##################################\n",
    "os_name = os.name\n",
    "# Windows = nt, [Linux, Apple] = posix. \n",
    "os_path = \"\\\\\" if os_name == \"nt\" else \"/\"  \n",
    "##################################################################################\n",
    "############################## ROBOFLOW  PARAMETERS ##############################\n",
    "roboflow_api_key = \"MJQUATZvpcKoBxRjLuXx\"\n",
    "roboflow_workspace_name = \"auv2024\"\n",
    "dataset_export_format = \"yolov8\"\n",
    "if is_front_camera_training:\n",
    "     roboflow_project_name = \"front-camera-sim\"\n",
    "else:\n",
    "     roboflow_project_name = \"down-camera-sim\"\n",
    "##################################################################################\n",
    "############################## TRAINING  PARAMETERS ##############################\n",
    "if is_front_camera_training:\n",
    "     target_classes = [\"bouy\", \"gate\", \"octagon-table\"]\n",
    "     model_save_filename = \"best_AUV_sim_front_camera_model.pt\"\n",
    "else: \n",
    "     target_classes = [\"bin\", \"lane-marker\", \"octagon-table\"]\n",
    "     model_save_filename = \"best_AUV_sim_down_camera_model.pt\"\n",
    "model_name = \"yolov8n.pt\"\n",
    "train_test_val_split = (0.7, 0.2, 0.1)\n",
    "epoch_increments = 200\n",
    "batch_size = -1 # Auto Mode (60% GPU Memory): Use batch=-1 to automatically \n",
    "                # adjust batch size for approximately 60% CUDA memory \n",
    "                # utilization.\n",
    "workers = 2\n",
    "cache = False\n",
    "pretrained = True\n",
    "imgsz = [480, 640]\n",
    "hsv_h = 0.015\n",
    "hsv_s = 0.3\n",
    "hsv_v = 0.3\n",
    "translate = 0.0\n",
    "scale = 0.0\n",
    "fliplr = 0.5\n",
    "flipud = 0.5\n",
    "mosaic = 0.75\n",
    "copy_paste = 0.1\n",
    "erasing = 0.0\n",
    "crop_fraction = 0.1\n",
    "degrees = 180\n",
    "##################################################################################\n",
    "######################### CUSTOM AUGMENTATION PARAMETERS #########################\n",
    "colorAugmentProb = 0.5\n",
    "noiseAugmentProb = 0.5\n",
    "resolutionAugmentProb = 0.0\n",
    "contrastAugmentProb = 0.5\n",
    "blurAugmentProb = 0.5\n",
    "brightnessAugmentProb = 0.5\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup python dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [\n",
    "     \"roboflow\", \n",
    "     \"albumentations\", \n",
    "     \"opencv-python\", \n",
    "     \"ultralytics\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    for package in packages:\n",
    "        subprocess.check_call([\"pip\", \"install\", package])\n",
    "    print(\"Packages installed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data\\augmented\n",
    "!mkdir data\\augmented\\train\n",
    "!mkdir data\\augmented\\test\n",
    "!mkdir data\\augmented\\val\n",
    "!mkdir data\\augmented\\train\\images\n",
    "!mkdir data\\augmented\\test\\images\n",
    "!mkdir data\\augmented\\val\\images\n",
    "!mkdir data\\augmented\\train\\labels\n",
    "!mkdir data\\augmented\\test\\labels\n",
    "!mkdir data\\augmented\\val\\labels\n",
    "!mkdir data\\raw\n",
    "!mkdir data\\raw\\images\n",
    "!mkdir data\\raw\\labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define YOLO classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_absolute_path = os.path.abspath(\"data\")\n",
    "print(f\"Data absolute path: {data_folder_absolute_path}.\")\n",
    "\n",
    "with open(\"data.yaml\", \"w+\") as f:\n",
    "    f.write(f\"train: {data_folder_absolute_path}{os_path}augmented{os_path}train{os_path}images\\n\")\n",
    "    f.write(f\"test: {data_folder_absolute_path}{os_path}augmented{os_path}test{os_path}images\\n\")\n",
    "    f.write(f\"val: {data_folder_absolute_path}{os_path}augmented{os_path}val{os_path}images\\n\")\n",
    "    f.write(f\"nc: {len(target_classes)}\\n\")\n",
    "    f.write(f\"names: {target_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments.\n",
    "def brightnessAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.ColorJitter(brightness=(1.5, 1.5), contrast=0, saturation=0, hue=0, always_apply=True)])\n",
    "        bright_img = transform(image=image)[\"image\"]\n",
    "        transform = A.Compose([A.augmentations.transforms.ColorJitter(brightness=(0.5, 0.5), contrast=0, saturation=0, hue=0, always_apply=True)])\n",
    "        dark_img = transform(image=image)[\"image\"]\n",
    "        out.append(bright_img)\n",
    "        out.append(dark_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering.\n",
    "def blurAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        ksize = (8, 8) # lower to lower blur\n",
    "        blurred_img = cv2.blur(image, ksize)\n",
    "        out.append(blurred_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure.\n",
    "def contrastAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.5, 0.5), saturation=0, hue=0, always_apply=True)])\n",
    "        decontrasted_img = transform(image=image)[\"image\"]\n",
    "        out.append(decontrasted_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds.\n",
    "def noiseAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.ISONoise(color_shift=(0.1, 0.1), intensity=(0.5, 0.5), always_apply=True)])\n",
    "        noisy_img = transform(image=image)[\"image\"]\n",
    "        out.append(noisy_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images.\n",
    "def resolutionAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.Downscale(scale_min=0.2, scale_max=0.2, always_apply=True)])\n",
    "        low_res_img = transform(image=image)[\"image\"]\n",
    "        out.append(low_res_img)\n",
    "    return out\n",
    "\n",
    "# Increase intensity of blues in given image.\n",
    "def make_bluer(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) # Split by channel.\n",
    "    img_b = np.uint16(img_b)\n",
    "    img_b += color_shift_intensity\n",
    "    np.clip(img_b, 0, 255, out=img_b)\n",
    "    img_b = np.uint8(img_b)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) # Merge adjusted channels.\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "# Increase intensity of greens in given image.\n",
    "def make_greener(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) # Split by channel.\n",
    "    img_g = np.uint16(img_g)\n",
    "    img_g += color_shift_intensity\n",
    "    np.clip(img_g, 0, 255, out=img_g)\n",
    "    img_g = np.uint8(img_g)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) # Merge adjusted channels.\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "# Given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation.\n",
    "def colorAugment(images):\n",
    "    out = []\n",
    "    color_shift_intensity = int(255*0.05)\n",
    "    for image in images:\n",
    "        blue_img = make_bluer(image, color_shift_intensity)\n",
    "        green_img = make_greener(image, color_shift_intensity)\n",
    "        out.append(blue_img)\n",
    "        out.append(green_img)\n",
    "    return out\n",
    "\n",
    "# Given a single image and augmentation function, displays the image before and images after augmentation.\n",
    "def visualizeAugmentation(img, aug):\n",
    "    # Show original image.\n",
    "    cv2.imshow(\"og\", img)\n",
    "    cv2.waitKey(0)\n",
    "    # Show all augmented images.\n",
    "    for augmented in aug([(img, \"\")])[1:]:\n",
    "        cv2.imshow(\"augmented\", augmented[0])\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(source_folder):\n",
    "    label_filenames = []\n",
    "    img_filenames = [f for f in os.listdir(source_folder + f\"{os_path}images\") if os.path.isfile(os.path.join(source_folder + f\"{os_path}images\", f))]\n",
    "    for img_filename in img_filenames:\n",
    "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
    "\n",
    "    return np.array(img_filenames), np.array(label_filenames)\n",
    "\n",
    "def split_file_names(images, labels, splits):\n",
    "    perm = np.random.permutation(len(images))\n",
    "    images = images[perm]\n",
    "    labels = labels[perm]\n",
    "    splits = [int(len(images)*s) for s in splits]\n",
    "    train_images = images[:splits[0]]\n",
    "    train_labels = labels[:splits[0]]\n",
    "    val_images = images[splits[0]: splits[0] + splits[1]]\n",
    "    val_labels = labels[splits[0]: splits[0] + splits[1]]\n",
    "    test_images = images[splits[0] + splits[1]:]\n",
    "    test_labels = labels[splits[0] + splits[1]:]\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "def get_augs(img_filename, source_folder):\n",
    "    img = cv2.imread(source_folder + f\"{os_path}images{os_path}\" + img_filename)\n",
    "    augs = [img]\n",
    "    if(np.random.rand() < colorAugmentProb):\n",
    "        augs = augs + colorAugment(augs)\n",
    "    if(np.random.rand() < noiseAugmentProb):\n",
    "        augs = augs + noiseAugment(augs)\n",
    "    if(np.random.rand() < resolutionAugmentProb):\n",
    "        augs = augs + resolutionAugment(augs)\n",
    "    if(np.random.rand() < contrastAugmentProb):\n",
    "        augs = augs + contrastAugment(augs)\n",
    "    if(np.random.rand() < blurAugmentProb):\n",
    "        augs = augs + blurAugment(augs)\n",
    "    if(np.random.rand() < brightnessAugmentProb):\n",
    "        augs = augs + brightnessAugment(augs)\n",
    "    return augs\n",
    "\n",
    "def do_augs_and_export(img_filenames, label_filenames, source_folder, output_folder):\n",
    "    name_num = 1\n",
    "    for (img_filename, label_filename) in zip(img_filenames, label_filenames):\n",
    "        augs = get_augs(img_filename, source_folder)\n",
    "        with open(source_folder + f\"{os_path}labels{os_path}\" + label_filename) as f:\n",
    "            #build array of bounding boxes (each line its own element)\n",
    "            bounding_boxes = f.read()\n",
    "        for aug in augs:\n",
    "            cv2.imwrite(output_folder + f\"{os_path}images{os_path}img\" + str(name_num) + \".png\", aug)\n",
    "            with open(output_folder + f\"{os_path}labels{os_path}img\" + str(name_num) + \".txt\", \"w+\") as f:\n",
    "                f.write(bounding_boxes)\n",
    "            name_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=roboflow_api_key)\n",
    "project = rf.workspace(roboflow_workspace_name).project(roboflow_project_name)\n",
    "latest_version = int(project.versions()[0].version)\n",
    "version = project.version(latest_version)\n",
    "dataset = version.download(dataset_export_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"{}-{}\".format(roboflow_project_name, latest_version)\n",
    "roboflow_folder_path = os.path.abspath(folder_name)\n",
    "data_folder_path = os.path.abspath(\"data\")\n",
    "\n",
    "print(f\"Roboflow folder name: {folder_name}.\")\n",
    "\n",
    "def copy_all_files(source, destination):\n",
    "     try:\n",
    "          # Ensure destination folder exists.\n",
    "          os.makedirs(destination, exist_ok=True)\n",
    "          # Copy all files from source to destination.\n",
    "          for filename in os.listdir(source):\n",
    "               source_file = os.path.join(source, filename)\n",
    "               if os.path.isfile(source_file):\n",
    "                    destination_file = os.path.join(destination, filename)\n",
    "                    shutil.move(source_file, destination_file)\n",
    "     except Exception as e:\n",
    "          print(f\"Error copying files: {e}.\")\n",
    "\n",
    "# Copy files from roboflow to data folder.\n",
    "for folder in [\"train\", \"valid\", \"test\"]:\n",
    "     print(f\"Moving {folder} folder...\")\n",
    "     copy_all_files(os.path.join(roboflow_folder_path, folder, \"images\"), \n",
    "                    os.path.join(data_folder_path, \"raw\", \"images\"))\n",
    "     copy_all_files(os.path.join(roboflow_folder_path, folder, \"labels\"), \n",
    "                    os.path.join(data_folder_path, \"raw\", \"labels\"))\n",
    "     print(f\"Moving {folder} folder completed.\")\n",
    "\n",
    "\n",
    "\n",
    "# Optional: Remove roboflow folder after copying files.\n",
    "try:\n",
    "     shutil.rmtree(folder_name)\n",
    "     print(f\"Removed folder: {folder_name}.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error removing folder: {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data, split into train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "out_folder = f\"data{os_path}augmented\"\n",
    "in_folder = f\"data{os_path}raw\"\n",
    "train = f\"{os_path}train\"\n",
    "val = f\"{os_path}val\"\n",
    "test = f\"{os_path}test\"\n",
    "\n",
    "raw_image_names, raw_label_names = get_file_names(in_folder)\n",
    "num_raw_samples = len(raw_image_names)\n",
    "train_images, train_labels, val_images, val_labels, test_images, test_labels = split_file_names(raw_image_names, raw_label_names, train_test_val_split)\n",
    "do_augs_and_export(train_images, train_labels, in_folder, out_folder + train)\n",
    "do_augs_and_export(val_images, val_labels, in_folder, out_folder + val)\n",
    "do_augs_and_export(test_images, test_labels, in_folder, out_folder + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_img_names, _ = get_file_names(out_folder + train)\n",
    "augmented_test_img_names, _ = get_file_names(out_folder + test)\n",
    "augmented_val_img_names, _ = get_file_names(out_folder + val)\n",
    "\n",
    "num_augmented_samples = len(augmented_train_img_names) + len(augmented_test_img_names) + len(augmented_val_img_names)\n",
    "\n",
    "print(f\"Augmentation completed: went from {num_raw_samples} samples to {num_augmented_samples} after augmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check CUDA dependencies and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (torch.cuda.is_available() and torch.cuda.device_count()):\n",
    "    raise RuntimeError(\"CUDA is NOT available. Please ensure that your system has a compatible GPU and the necessary drivers are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_folder = \"runs\"\n",
    "detect_folder = \"detect\"\n",
    "\n",
    "if os.path.exists(runs_folder):\n",
    "    shutil.rmtree(runs_folder)\n",
    "\n",
    "os.makedirs(os.path.join(runs_folder, detect_folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml_file_absolute_path = os.path.abspath(\"data.yaml\")\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\") # load a pretrained model.\n",
    "\n",
    "# Start the training process.\n",
    "while True:\n",
    "    try:\n",
    "        model.train(\n",
    "            data=data_yaml_file_absolute_path,\n",
    "            epochs=epoch_increments,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch_size,\n",
    "            pretrained=pretrained,\n",
    "            task=\"detect\",\n",
    "            cache=cache,\n",
    "            workers=workers,\n",
    "            hsv_h=hsv_h,\n",
    "            hsv_s=hsv_s,\n",
    "            hsv_v=hsv_v,\n",
    "            translate=translate,\n",
    "            scale=scale,\n",
    "            fliplr=fliplr,\n",
    "            flipud=flipud,\n",
    "            mosaic=mosaic,\n",
    "            copy_paste=copy_paste,\n",
    "            erasing=erasing,\n",
    "            crop_fraction=crop_fraction,\n",
    "            degrees=degrees\n",
    "        )\n",
    "        shutil.copyfile(f\"runs{os_path}detect{os_path}train{os_path}weights{os_path}best.pt\", model_save_filename)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Caught a RuntimeError: {e}.\")\n",
    "        break  # Break out of the loop if an error occurs to prevent infinite loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
