{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "is_front_camera_training = False  # Change it to False if training for down cmaera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# OS PARAMETERS ##################################\n",
    "os_name = os.name\n",
    "# Windows = nt, [Linux, Apple] = posix. \n",
    "os_path = \"\\\\\" if os_name == \"nt\" else \"/\"  \n",
    "##################################################################################\n",
    "############################## ROBOFLOW  PARAMETERS ##############################\n",
    "roboflow_api_key = \"MJQUATZvpcKoBxRjLuXx\"\n",
    "roboflow_workspace_name = \"auv2024\"\n",
    "dataset_export_format = \"yolov8\"\n",
    "if is_front_camera_training:\n",
    "     roboflow_project_name = \"front-camera-sim\"\n",
    "else:\n",
    "     roboflow_project_name = \"down-camera-sim\"\n",
    "##################################################################################\n",
    "############################## TRAINING  PARAMETERS ##############################\n",
    "if is_front_camera_training:\n",
    "     target_classes = [\"bouy\", \"gate\", \"octagon-table\"]\n",
    "     model_save_filename = \"best_AUV_sim_front_camera_model.pt\"\n",
    "else: \n",
    "     target_classes = [\"bin\", \"lane-marker\", \"octagon-table\"]\n",
    "     model_save_filename = \"best_AUV_sim_down_camera_model.pt\"\n",
    "model_name = \"yolov8n.pt\"\n",
    "train_test_val_split = (0.7, 0.2, 0.1)\n",
    "epoch_increments = 200\n",
    "batch_size = -1 # Auto Mode (60% GPU Memory): Use batch=-1 to automatically \n",
    "                # adjust batch size for approximately 60% CUDA memory \n",
    "                # utilization.\n",
    "workers = 2\n",
    "cache = False\n",
    "pretrained = True\n",
    "imgsz = [480, 640]\n",
    "hsv_h = 0.015\n",
    "hsv_s = 0.3\n",
    "hsv_v = 0.3\n",
    "translate = 0.0\n",
    "scale = 0.0\n",
    "fliplr = 0.5\n",
    "flipud = 0.5\n",
    "mosaic = 0.1\n",
    "copy_paste = 0.0\n",
    "erasing = 0.0\n",
    "crop_fraction = 0.1\n",
    "degrees = 180\n",
    "##################################################################################\n",
    "######################### CUSTOM AUGMENTATION PARAMETERS #########################\n",
    "colorAugmentProb = 0.5\n",
    "noiseAugmentProb = 0.5\n",
    "resolutionAugmentProb = 0.0\n",
    "contrastAugmentProb = 0.5\n",
    "blurAugmentProb = 0.5\n",
    "brightnessAugmentProb = 0.5\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup python dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [\n",
    "     \"roboflow\", \n",
    "     \"albumentations\", \n",
    "     \"opencv-python\", \n",
    "     \"ultralytics\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    for package in packages:\n",
    "        subprocess.check_call([\"pip\", \"install\", package])\n",
    "    print(\"Packages installed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.11 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data\\augmented\n",
    "!mkdir data\\augmented\\images\n",
    "!mkdir data\\augmented\\labels\n",
    "!mkdir data\\augmented\\train\n",
    "!mkdir data\\augmented\\test\n",
    "!mkdir data\\augmented\\val\n",
    "!mkdir data\\augmented\\train\\images\n",
    "!mkdir data\\augmented\\test\\images\n",
    "!mkdir data\\augmented\\val\\images\n",
    "!mkdir data\\augmented\\train\\labels\n",
    "!mkdir data\\augmented\\test\\labels\n",
    "!mkdir data\\augmented\\val\\labels\n",
    "!mkdir data\\raw\n",
    "!mkdir data\\raw\\images\n",
    "!mkdir data\\raw\\labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define YOLO classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data absolute path: c:\\Users\\poten\\AUV-2024\\catkin_ws\\src\\vision\\model_pipeline\\data.\n"
     ]
    }
   ],
   "source": [
    "data_folder_absolute_path = os.path.abspath(\"data\")\n",
    "print(f\"Data absolute path: {data_folder_absolute_path}.\")\n",
    "\n",
    "with open(\"data.yaml\", \"w+\") as f:\n",
    "    f.write(f\"train: {data_folder_absolute_path}{os_path}augmented{os_path}train{os_path}images\\n\")\n",
    "    f.write(f\"test: {data_folder_absolute_path}{os_path}augmented{os_path}test{os_path}images\\n\")\n",
    "    f.write(f\"val: {data_folder_absolute_path}{os_path}augmented{os_path}val{os_path}images\\n\")\n",
    "    f.write(f\"nc: {len(target_classes)}\\n\")\n",
    "    f.write(f\"names: {target_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments.\n",
    "def brightnessAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.ColorJitter(brightness=(1.5, 1.5), contrast=0, saturation=0, hue=0, always_apply=True)])\n",
    "        bright_img = transform(image=image)[\"image\"]\n",
    "        transform = A.Compose([A.augmentations.transforms.ColorJitter(brightness=(0.5, 0.5), contrast=0, saturation=0, hue=0, always_apply=True)])\n",
    "        dark_img = transform(image=image)[\"image\"]\n",
    "        out.append(bright_img)\n",
    "        out.append(dark_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering.\n",
    "def blurAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        ksize = (8, 8) # lower to lower blur\n",
    "        blurred_img = cv2.blur(image, ksize)\n",
    "        out.append(blurred_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure.\n",
    "def contrastAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.5, 0.5), saturation=0, hue=0, always_apply=True)])\n",
    "        decontrasted_img = transform(image=image)[\"image\"]\n",
    "        out.append(decontrasted_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds.\n",
    "def noiseAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.ISONoise(color_shift=(0.1, 0.1), intensity=(0.5, 0.5), always_apply=True)])\n",
    "        noisy_img = transform(image=image)[\"image\"]\n",
    "        out.append(noisy_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images.\n",
    "def resolutionAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.augmentations.transforms.Downscale(scale_min=0.2, scale_max=0.2, always_apply=True)])\n",
    "        low_res_img = transform(image=image)[\"image\"]\n",
    "        out.append(low_res_img)\n",
    "    return out\n",
    "\n",
    "# Increase intensity of blues in given image.\n",
    "def make_bluer(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) # Split by channel.\n",
    "    img_b = np.uint16(img_b)\n",
    "    img_b += color_shift_intensity\n",
    "    np.clip(img_b, 0, 255, out=img_b)\n",
    "    img_b = np.uint8(img_b)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) # Merge adjusted channels.\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "# Increase intensity of greens in given image.\n",
    "def make_greener(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) # Split by channel.\n",
    "    img_g = np.uint16(img_g)\n",
    "    img_g += color_shift_intensity\n",
    "    np.clip(img_g, 0, 255, out=img_g)\n",
    "    img_g = np.uint8(img_g)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) # Merge adjusted channels.\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "# Given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation.\n",
    "def colorAugment(images):\n",
    "    out = []\n",
    "    color_shift_intensity = int(255*0.05)\n",
    "    for image in images:\n",
    "        blue_img = make_bluer(image, color_shift_intensity)\n",
    "        green_img = make_greener(image, color_shift_intensity)\n",
    "        out.append(blue_img)\n",
    "        out.append(green_img)\n",
    "    return out\n",
    "\n",
    "# Given a single image and augmentation function, displays the image before and images after augmentation.\n",
    "def visualizeAugmentation(img, aug):\n",
    "    # Show original image.\n",
    "    cv2.imshow(\"og\", img)\n",
    "    cv2.waitKey(0)\n",
    "    # Show all augmented images.\n",
    "    for augmented in aug([(img, \"\")])[1:]:\n",
    "        cv2.imshow(\"augmented\", augmented[0])\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(source_folder):\n",
    "    label_filenames = []\n",
    "    img_filenames = [f for f in os.listdir(source_folder + f\"{os_path}images\") if os.path.isfile(os.path.join(source_folder + f\"{os_path}images\", f))]\n",
    "    for img_filename in img_filenames:\n",
    "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
    "\n",
    "    return np.array(img_filenames), np.array(label_filenames)\n",
    "\n",
    "def split_and_move_data(source_dir, dest_dir, split_ratio=(0.7, 0.2, 0.1)):\n",
    "    source_image_dir = f\"{source_dir}{os_path}images\"\n",
    "    source_label_dir = f\"{source_dir}{os_path}labels\"\n",
    "    # Get list of image and label files.\n",
    "    image_files = sorted(os.listdir(source_image_dir))\n",
    "    label_files = sorted(os.listdir(source_label_dir))\n",
    "\n",
    "    # Shuffle the indices.\n",
    "    indices = np.arange(len(image_files))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Calculate split indices.\n",
    "    total_count = len(image_files)\n",
    "    train_end = int(total_count * split_ratio[0])\n",
    "    val_end = train_end + int(total_count * split_ratio[1])\n",
    "\n",
    "    train_indices = indices[:train_end]\n",
    "    val_indices = indices[train_end:val_end]\n",
    "    test_indices = indices[val_end:]\n",
    "\n",
    "    # Function to move files\n",
    "    def move_files(indices, split):\n",
    "        for i in indices:\n",
    "            shutil.move(os.path.join(source_image_dir, image_files[i]), \n",
    "                        os.path.join(dest_dir, split, 'images', image_files[i]))\n",
    "            shutil.move(os.path.join(source_label_dir, label_files[i]), \n",
    "                        os.path.join(dest_dir, split, 'labels', label_files[i]))\n",
    "\n",
    "    # Move files to corresponding folders\n",
    "    move_files(train_indices, 'train')\n",
    "    move_files(val_indices, 'val')\n",
    "    move_files(test_indices, 'test')\n",
    "\n",
    "def get_augs(img_filename, source_folder):\n",
    "    img = cv2.imread(source_folder + f\"{os_path}images{os_path}\" + img_filename)\n",
    "    augs = [img]\n",
    "    if(np.random.rand() < colorAugmentProb):\n",
    "        augs = augs + colorAugment(augs)\n",
    "    if(np.random.rand() < noiseAugmentProb):\n",
    "        augs = augs + noiseAugment(augs)\n",
    "    if(np.random.rand() < resolutionAugmentProb):\n",
    "        augs = augs + resolutionAugment(augs)\n",
    "    if(np.random.rand() < contrastAugmentProb):\n",
    "        augs = augs + contrastAugment(augs)\n",
    "    if(np.random.rand() < blurAugmentProb):\n",
    "        augs = augs + blurAugment(augs)\n",
    "    if(np.random.rand() < brightnessAugmentProb):\n",
    "        augs = augs + brightnessAugment(augs)\n",
    "    return augs\n",
    "\n",
    "def do_augs_and_export(img_filenames, label_filenames, source_folder, output_folder):\n",
    "    name_num = 1\n",
    "    for (img_filename, label_filename) in zip(img_filenames, label_filenames):\n",
    "        augs = get_augs(img_filename, source_folder)\n",
    "        with open(source_folder + f\"{os_path}labels{os_path}\" + label_filename) as f:\n",
    "            #build array of bounding boxes (each line its own element)\n",
    "            bounding_boxes = f.read()\n",
    "        for aug in augs:\n",
    "            cv2.imwrite(output_folder + f\"{os_path}images{os_path}img\" + str(name_num) + \".png\", aug)\n",
    "            with open(output_folder + f\"{os_path}labels{os_path}img\" + str(name_num) + \".txt\", \"w+\") as f:\n",
    "                f.write(bounding_boxes)\n",
    "            name_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.35, to fix: `pip install ultralytics==8.0.196`\n",
      "Exporting format yolov8 in progress : 85.0%\n",
      "Version export complete for yolov8 format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in down-camera-sim-8 to yolov8:: 100%|██████████| 6980/6980 [00:00<00:00, 23274.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to down-camera-sim-8 in yolov8:: 100%|██████████| 840/840 [00:00<00:00, 3765.10it/s]\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=roboflow_api_key)\n",
    "project = rf.workspace(roboflow_workspace_name).project(roboflow_project_name)\n",
    "latest_version = int(project.versions()[0].version)\n",
    "version = project.version(latest_version)\n",
    "dataset = version.download(dataset_export_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roboflow folder name: down-camera-sim-8.\n",
      "Moving train folder...\n",
      "Moving train folder completed.\n",
      "Moving valid folder...\n",
      "Moving valid folder completed.\n",
      "Moving test folder...\n",
      "Moving test folder completed.\n",
      "Removed folder: down-camera-sim-8.\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"{}-{}\".format(roboflow_project_name, latest_version)\n",
    "roboflow_folder_path = os.path.abspath(folder_name)\n",
    "data_folder_path = os.path.abspath(\"data\")\n",
    "\n",
    "print(f\"Roboflow folder name: {folder_name}.\")\n",
    "\n",
    "def copy_all_files(source, destination):\n",
    "     try:\n",
    "          # Ensure destination folder exists.\n",
    "          os.makedirs(destination, exist_ok=True)\n",
    "          # Copy all files from source to destination.\n",
    "          for filename in os.listdir(source):\n",
    "               source_file = os.path.join(source, filename)\n",
    "               if os.path.isfile(source_file):\n",
    "                    destination_file = os.path.join(destination, filename)\n",
    "                    shutil.move(source_file, destination_file)\n",
    "     except Exception as e:\n",
    "          print(f\"Error copying files: {e}.\")\n",
    "\n",
    "# Copy files from roboflow to data folder.\n",
    "for folder in [\"train\", \"valid\", \"test\"]:\n",
    "     print(f\"Moving {folder} folder...\")\n",
    "     copy_all_files(os.path.join(roboflow_folder_path, folder, \"images\"), \n",
    "                    os.path.join(data_folder_path, \"raw\", \"images\"))\n",
    "     copy_all_files(os.path.join(roboflow_folder_path, folder, \"labels\"), \n",
    "                    os.path.join(data_folder_path, \"raw\", \"labels\"))\n",
    "     print(f\"Moving {folder} folder completed.\")\n",
    "\n",
    "# Optional: Remove roboflow folder after copying files.\n",
    "try:\n",
    "     shutil.rmtree(folder_name)\n",
    "     print(f\"Removed folder: {folder_name}.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error removing folder: {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data, split into train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "out_folder = f\"data{os_path}augmented\"\n",
    "in_folder = f\"data{os_path}raw\"\n",
    "train = f\"{os_path}train\"\n",
    "val = f\"{os_path}val\"\n",
    "test = f\"{os_path}test\"\n",
    "\n",
    "raw_image_names, raw_label_names = get_file_names(in_folder)\n",
    "num_raw_samples = len(raw_image_names)\n",
    "do_augs_and_export(raw_image_names, raw_label_names, in_folder, out_folder)\n",
    "split_and_move_data(out_folder, out_folder)\n",
    "\n",
    "os.rmdir(f\"data{os_path}augmented{os_path}images\")\n",
    "os.rmdir(f\"data{os_path}augmented{os_path}labels\")\n",
    "shutil.rmtree(in_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation completed: went from 414 samples to 6178 after augmentation.\n"
     ]
    }
   ],
   "source": [
    "augmented_train_img_names, _ = get_file_names(out_folder + train)\n",
    "augmented_test_img_names, _ = get_file_names(out_folder + test)\n",
    "augmented_val_img_names, _ = get_file_names(out_folder + val)\n",
    "\n",
    "num_augmented_samples = len(augmented_train_img_names) + len(augmented_test_img_names) + len(augmented_val_img_names)\n",
    "\n",
    "print(f\"Augmentation completed: went from {num_raw_samples} samples to {num_augmented_samples} after augmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check CUDA dependencies and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (torch.cuda.is_available() and torch.cuda.device_count()):\n",
    "    raise RuntimeError(\"CUDA is NOT available. Please ensure that your system has a compatible GPU and the necessary drivers are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_folder = \"runs\"\n",
    "detect_folder = \"detect\"\n",
    "\n",
    "if os.path.exists(runs_folder):\n",
    "    shutil.rmtree(runs_folder)\n",
    "\n",
    "os.makedirs(os.path.join(runs_folder, detect_folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml_file_absolute_path = os.path.abspath(\"data.yaml\")\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\") # load a pretrained model.\n",
    "\n",
    "# Start the training process.\n",
    "while True:\n",
    "    try:\n",
    "        model.train(\n",
    "            data=data_yaml_file_absolute_path,\n",
    "            epochs=epoch_increments,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch_size,\n",
    "            pretrained=pretrained,\n",
    "            task=\"detect\",\n",
    "            cache=cache,\n",
    "            workers=workers,\n",
    "            hsv_h=hsv_h,\n",
    "            hsv_s=hsv_s,\n",
    "            hsv_v=hsv_v,\n",
    "            translate=translate,\n",
    "            scale=scale,\n",
    "            fliplr=fliplr,\n",
    "            flipud=flipud,\n",
    "            mosaic=mosaic,\n",
    "            copy_paste=copy_paste,\n",
    "            erasing=erasing,\n",
    "            crop_fraction=crop_fraction,\n",
    "            degrees=degrees\n",
    "        )\n",
    "        shutil.copyfile(f\"runs{os_path}detect{os_path}train{os_path}weights{os_path}best.pt\", model_save_filename)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Caught a RuntimeError: {e}.\")\n",
    "        break  # Break out of the loop if an error occurs to prevent infinite loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
