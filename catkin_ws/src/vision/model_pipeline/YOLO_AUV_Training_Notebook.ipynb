{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkA2uszFgZdm"
      },
      "source": [
        "# DEFINE PARAMETERS (this is the only thing to modify if you just want to train a model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZTwtOPQgY3A"
      },
      "outputs": [],
      "source": [
        "# Roboflow parameters\n",
        "roboflow_api_key = \"MJQUATZvpcKoBxRjLuXx\"\n",
        "roboflow_workspace_name = \"auv2024\"\n",
        "roboflow_project_name = \"auv-frontcam-visionv2\"\n",
        "roboflow_project_version = 2\n",
        "\n",
        "# Training parameters\n",
        "target_classes = [\"Buoy\", \"Gate\", \"Lane Marker\"]\n",
        "train_test_val_split = (0.7, 0.2, 0.1)\n",
        "model_save_filename = \"best_AUV_sim_front_cam_model.pt\"\n",
        "epoch_increments = 1 # save the model weights to google drive every `epoch_increments` epochs\n",
        "batch_size = 16\n",
        "\n",
        "# Custom augmentation parameters\n",
        "colorAugmentProb = 0.5\n",
        "noiseAugmentProb = 0.5\n",
        "resolutionAugmentProb = 0.5\n",
        "contrastAugmentProb = 0.5\n",
        "blurAugmentProb = 0.5\n",
        "brightnessAugmentProb = 0.0\n",
        "\n",
        "# WARNING: do not change these \"randomly\", check the YoloV8 docs for what these parameters affect before modifying (these values have worked well)\n",
        "# See the last cell for where these parameters are used in the model\n",
        "degrees = 360\n",
        "flipud = 0.5\n",
        "fliplr = 0.5\n",
        "max_perspective_change = 0.001\n",
        "max_translate = 0.1\n",
        "max_scale_change = 0.3\n",
        "mosaic = 0.5\n",
        "mixup = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTYLP5gRgelD"
      },
      "source": [
        "# IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et9kLMSDbkvt"
      },
      "source": [
        "## Mount Drive, setup Python dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma-GR0Q5Qn4k",
        "outputId": "e2fa4fe5-69c5-4c2d-84bf-1a78bbabf1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "#fixes bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58F4m91jwxYX",
        "outputId": "ac44a553-1aac-44df-d215-95e919de850c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.26)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.50.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.0.74)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.10.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.34-py3-none-any.whl (723 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.1/723.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.1.34\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/train’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/test’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/val’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/train/images’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/test/images’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/val/images’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/train/labels’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/test/labels’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/val/labels’: File exists\n",
            "rm: cannot remove 'sample_data': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "!pip install albumentations\n",
        "!pip install opencv-python\n",
        "!pip install ultralytics\n",
        "\n",
        "!mkdir data\n",
        "!mkdir data/augmented\n",
        "!mkdir data/augmented/train\n",
        "!mkdir data/augmented/test\n",
        "!mkdir data/augmented/val\n",
        "!mkdir data/augmented/train/images\n",
        "!mkdir data/augmented/test/images\n",
        "!mkdir data/augmented/val/images\n",
        "!mkdir data/augmented/train/labels\n",
        "!mkdir data/augmented/test/labels\n",
        "!mkdir data/augmented/val/labels\n",
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN29TW2MxhB9"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from roboflow import Roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVo9YblEb93v"
      },
      "source": [
        "## Define YOLO classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M03OBN22xr4s"
      },
      "outputs": [],
      "source": [
        "with open('data.yaml', 'w+') as f:\n",
        "    f.write(\"train: /content/data/augmented/train/images\\n\")\n",
        "    f.write(\"test: /content/data/augmented/test/images\\n\")\n",
        "    f.write(\"val: /content/data/augmented/val/images\\n\")\n",
        "    f.write(\"nc: {}\\n\".format(len(target_classes)))\n",
        "    f.write('names: {}'.format(target_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf6GvElFcDgY"
      },
      "source": [
        "## Define augmentation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRAkj-Gzxu0m"
      },
      "outputs": [],
      "source": [
        "#given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments\n",
        "def brightnessAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(1.05, 1.05), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        bright_img = transform(image=image)[\"image\"]\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(0.95, 0.95), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        dark_img = transform(image=image)[\"image\"]\n",
        "        out.append(bright_img)\n",
        "        out.append(dark_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering\n",
        "def blurAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        ksize = (10, 10) # lower to lower blur\n",
        "        blurred_img = cv2.blur(image, ksize)\n",
        "        out.append(blurred_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure\n",
        "def contrastAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.1, 0.1), saturation=0, hue=0, always_apply=True) ])\n",
        "        decontrasted_img = transform(image=image)[\"image\"]\n",
        "        out.append(decontrasted_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds\n",
        "def noiseAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ISONoise(color_shift=(0.01, 0.01), intensity=(0.8, 0.8), always_apply=True) ])\n",
        "        noisy_img = transform(image=image)[\"image\"]\n",
        "        out.append(noisy_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images\n",
        "def resolutionAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        #interpolation=A.augmentations.transforms.Interpolation(downscale=cv2.INTER_NEAREST, upscale=cv2.INTER_NEAREST)\n",
        "        transform = A.Compose([ A.augmentations.transforms.Downscale(scale_min=0.25, scale_max=0.25, always_apply=True) ])\n",
        "        low_res_img = transform(image=image)[\"image\"]\n",
        "        out.append(low_res_img)\n",
        "    return out\n",
        "\n",
        "#increase intensity of blues in given image\n",
        "def make_bluer(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_b = np.uint16(img_b)\n",
        "    img_b += color_shift_intensity\n",
        "    np.clip(img_b, 0, 255, out=img_b)\n",
        "    img_b = np.uint8(img_b)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#increase intensity of greens in given image\n",
        "def make_greener(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_g = np.uint16(img_g)\n",
        "    img_g += color_shift_intensity\n",
        "    np.clip(img_g, 0, 255, out=img_g)\n",
        "    img_g = np.uint8(img_g)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation\n",
        "def colorAugment(images):\n",
        "    out = []\n",
        "    color_shift_intensity = int(255*0.1)\n",
        "    for image in images:\n",
        "        blue_img = make_bluer(image, color_shift_intensity)\n",
        "        green_img = make_greener(image, color_shift_intensity)\n",
        "        out.append(blue_img)\n",
        "        out.append(green_img)\n",
        "    return out\n",
        "\n",
        "#given a single image and augmentation function, displays the image before and images after augmentation\n",
        "def visualizeAugmentation(img, aug):\n",
        "    #show original image\n",
        "    cv2.imshow('og', img)\n",
        "    cv2.waitKey(0)\n",
        "    #show all augmented images\n",
        "    for augmented in aug([(img, \"\")])[1:]:\n",
        "        cv2.imshow('augmented',augmented[0])\n",
        "        cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o94FDfOVyBvu"
      },
      "outputs": [],
      "source": [
        "def get_file_names(source_folder):\n",
        "    label_filenames = []\n",
        "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
        "    for img_filename in img_filenames:\n",
        "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
        "\n",
        "    return np.array(img_filenames), np.array(label_filenames)\n",
        "\n",
        "def split_file_names(images,labels,splits):\n",
        "    perm = np.random.permutation(len(images))\n",
        "    images = images[perm]\n",
        "    labels = labels[perm]\n",
        "    splits = [int(len(images)*s) for s in splits]\n",
        "    train_images = images[:splits[0]]\n",
        "    train_labels = labels[:splits[0]]\n",
        "    val_images = images[splits[0]: splits[0] + splits[1]]\n",
        "    val_labels = labels[splits[0]: splits[0] + splits[1]]\n",
        "    test_images = images[splits[0] + splits[1]:]\n",
        "    test_labels = labels[splits[0] + splits[1]:]\n",
        "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
        "\n",
        "def get_augs(img_filename,source_folder):\n",
        "    img = cv2.imread(source_folder + '/images/' + img_filename)\n",
        "    augs = [img]\n",
        "    if(np.random.rand() < colorAugmentProb):\n",
        "        augs = augs + colorAugment(augs)\n",
        "    if(np.random.rand() < noiseAugmentProb):\n",
        "        augs = augs + noiseAugment(augs)\n",
        "    if(np.random.rand() < resolutionAugmentProb):\n",
        "        augs = augs + resolutionAugment(augs)\n",
        "    if(np.random.rand() < contrastAugmentProb):\n",
        "        augs = augs + contrastAugment(augs)\n",
        "    if(np.random.rand() < blurAugmentProb):\n",
        "        augs = augs + blurAugment(augs)\n",
        "    if(np.random.rand() < brightnessAugmentProb):\n",
        "        augs = augs + brightnessAugment(augs)\n",
        "    return augs\n",
        "\n",
        "def do_augs_and_export(img_filenames,label_filenames,source_folder,output_folder):\n",
        "    name_num = 1\n",
        "    for (img_filename,label_filename) in zip(img_filenames,label_filenames):\n",
        "        augs = get_augs(img_filename,source_folder)\n",
        "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
        "            #build array of bounding boxes (each line its own element)\n",
        "            bounding_boxes = f.read()\n",
        "        for aug in augs:\n",
        "            cv2.imwrite(output_folder + '/images/img' + str(name_num) + '.png', aug)\n",
        "            with open(output_folder + '/labels/img' + str(name_num) + '.txt',\"w+\") as f:\n",
        "                f.write(bounding_boxes)\n",
        "            name_num+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gg8L31ZcdXv"
      },
      "source": [
        "## Download dataset from RoboFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p69--bQOySln",
        "outputId": "a449bd2a-41e3-41aa-ca24-3af4049c4e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in auv-frontcam-visionv2-2 to yolov5pytorch:: 100%|██████████| 2849/2849 [00:00<00:00, 10085.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to auv-frontcam-visionv2-2 in yolov5pytorch:: 100%|██████████| 280/280 [00:00<00:00, 5157.71it/s]\n"
          ]
        }
      ],
      "source": [
        "rf = Roboflow(api_key=roboflow_api_key)\n",
        "project = rf.workspace(roboflow_workspace_name).project(roboflow_project_name)\n",
        "version = project.version(roboflow_project_version)\n",
        "dataset = version.download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2wDV0S-z5ft",
        "outputId": "2b6ab4a3-6081-46c8-a118-74398f46b055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auv-frontcam-visionv2-2\n"
          ]
        }
      ],
      "source": [
        "folder_name = \"{}-{}\".format(roboflow_project_name, roboflow_project_version)\n",
        "\n",
        "print(folder_name)\n",
        "\n",
        "!mv /content/$folder_name/train/ /content/data/raw\n",
        "!mv /content/$folder_name/test/images/* /content/data/raw/images/\n",
        "!mv /content/$folder_name/valid/images/* /content/data/raw/images/\n",
        "!mv /content/$folder_name/test/labels/* /content/data/raw/labels/\n",
        "!mv /content/$folder_name/valid/labels/* /content/data/raw/labels/\n",
        "!rm -r $folder_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3uZyY_uer3H"
      },
      "source": [
        "## Augment data, split into train/test/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkd3wksY0k2i",
        "outputId": "87d09b69-4bd9-47a7-ac4a-8c0f75018ee7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmentation completed. Went from 134 raw samples to a total of 1421 after augmentation.\n"
          ]
        }
      ],
      "source": [
        "out_folder = \"data/augmented\"\n",
        "in_folder = \"data/raw\"\n",
        "\n",
        "img_names, label_names = get_file_names(in_folder)\n",
        "num_raw_samples = len(img_names)\n",
        "train_images, train_labels, val_images, val_labels, test_images, test_labels = split_file_names(img_names,label_names,train_test_val_split)\n",
        "do_augs_and_export(train_images,train_labels,in_folder,out_folder + \"/train\")\n",
        "do_augs_and_export(val_images,val_labels,in_folder,out_folder + \"/val\")\n",
        "do_augs_and_export(test_images,test_labels,in_folder,out_folder + \"/test\")\n",
        "\n",
        "augmented_train_img_names, _ = get_file_names(out_folder + \"/train\")\n",
        "augmented_test_img_names, _ = get_file_names(out_folder + \"/test\")\n",
        "augmented_val_img_names, _ = get_file_names(out_folder + \"/val\")\n",
        "\n",
        "num_augmented_samples = len(augmented_train_img_names) + len(augmented_test_img_names) + len(augmented_val_img_names)\n",
        "\n",
        "print(\"Augmentation completed. Went from {} raw samples to a total of {} after augmentation.\".format(num_raw_samples, num_augmented_samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpkZGNqWgQ7E"
      },
      "source": [
        "# Check CUDA dependencies and start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AotbSTe2pLU"
      },
      "outputs": [],
      "source": [
        "CUDA_setup_is_valid = torch.cuda.is_available() and torch.cuda.device_count() > 0\n",
        "\n",
        "if not CUDA_setup_is_valid:\n",
        "  raise Exception('No CUDA device detected. Make sure you set hardware accelerator to GPU in Edit > Notebook Settings > Hardware Accelerator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9JgHc3R3950"
      },
      "outputs": [],
      "source": [
        "!rm -r runs/detect/train*\n",
        "!mkdir runs\n",
        "!mkdir runs/detect\n",
        "\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\") #load a pretrained model\n",
        "\n",
        "# Start the training process\n",
        "while True:\n",
        "    try:\n",
        "        model.train(\n",
        "            data=\"data.yaml\",\n",
        "            epochs=epoch_increments,\n",
        "            device=0,\n",
        "            batch=batch_size,\n",
        "            degrees=degrees,\n",
        "            flipud=flipud,\n",
        "            fliplr=fliplr,\n",
        "            perspective=max_perspective_change,\n",
        "            translate=max_translate,\n",
        "            scale=max_scale_change,\n",
        "            mosaic=mosaic,\n",
        "            mixup=mixup,\n",
        "            pretrained=True,\n",
        "            task='detect',\n",
        "        )\n",
        "        shutil.copyfile(\"runs/detect/train/weights/best.pt\", \"/content/drive/My Drive/{}\".format(model_save_filename))\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Caught a RuntimeError: {e}\")\n",
        "        break  # Break out of the loop if an error occurs to prevent infinite loop\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MTYLP5gRgelD"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
