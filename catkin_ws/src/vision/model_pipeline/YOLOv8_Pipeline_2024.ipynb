{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Main task:** train front cam with real life images to identify the following classes:\n",
        "\n",
        " [\"Abydos Symbol\", \"Buoy\", \"Earth Symbol\", \"Gate\", \"Lane Marker\", \"Octagon Table\"]\n",
        "\n",
        "** Secondary task:** train different model for the down cam to identify the following classes:\n",
        "  [\"Lane Marker\", \"Octagon Table\"],\n",
        "\n",
        "\n",
        "TODO:\n",
        "*   Make shuffle function get a similar similar sample size of images for every class in the train, test and val splits. Split by class and then combine together to make sure the datasets are balanced\n",
        "\n"
      ],
      "metadata": {
        "id": "_22YU2slbQv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Duke dataset**\n",
        "*    \"pool...\" = real image\n",
        "*    \"camera...\" = simulation"
      ],
      "metadata": {
        "id": "2qAELukyWkyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**More datasets!**\n",
        "\n",
        "https://github.com/beaverauv/robosub_transdec_dataset/tree/master\n",
        "\n",
        "https://app.box.com/folder/218274654447"
      ],
      "metadata": {
        "id": "_nnJpKjwUxKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Avoid runtime from disconnecting when training model:**\n",
        "\n",
        "Copy paste the following into the console (ctrl + shift + i):\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#toolbar-add-code\").click()\n",
        "}setInterval(ClickConnect,120000)\n",
        "\n",
        "https://maneeshkadanasseril.medium.com/how-to-stop-colab-from-disconnecting-2021-solution-ae5721e3838#:~:text=If%20you%20are%20not%20interacting,its%20runtime%20is%20automatically%20disconnected.&text=The%20only%20solution%20to,this%20is%20not%20always%20possible."
      ],
      "metadata": {
        "id": "zW0VN98BwogV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAQ76bSTy48-"
      },
      "source": [
        "# Install dependencies, set up folder structure, import necessary librairies, generate data.yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "editable": true,
        "id": "I2wYwdPAyklw",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60529c8a-af0e-4d4f-ac40-78b97980dad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.1.78)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.221-py3-none-any.whl (646 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m646.6/646.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.221\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations\n",
        "!pip install opencv-python\n",
        "!pip install ultralytics\n",
        "!mkdir data\n",
        "!mkdir data/augmented\n",
        "# !mkdir data/raw\n",
        "!mkdir data/augmented/train\n",
        "!mkdir data/augmented/test\n",
        "!mkdir data/augmented/val\n",
        "!mkdir data/augmented/train/images\n",
        "!mkdir data/augmented/test/images\n",
        "!mkdir data/augmented/val/images\n",
        "!mkdir data/augmented/train/labels\n",
        "!mkdir data/augmented/test/labels\n",
        "!mkdir data/augmented/val/labels\n",
        "# !mkdir data/raw/images\n",
        "# !mkdir data/raw/labels\n",
        "# !rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "editable": true,
        "id": "V3-T5zOB0sEi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import shutil\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "editable": true,
        "id": "N0SHMX1C2ZuL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "with open('data.yaml', 'w+') as f:\n",
        "    f.write(\"train: /content/data/augmented/train/images\\n\")\n",
        "    f.write(\"test: /content/data/augmented/test/images\\n\")\n",
        "    f.write(\"val: /content/data/augmented/val/images\\n\")\n",
        "    f.write(\"nc: 6\\n\")\n",
        "    f.write('names: [\"Abydos Symbol\", \"Buoy\", \"Earth Symbol\", \"Gate\", \"Lane Marker\", \"Octagon Table\"]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COpq9wZczt1G"
      },
      "source": [
        "# Augment data in /raw folder, put augmented dataset in /augmented folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHa1-UEe0FuN"
      },
      "source": [
        "Define individual augmentation functions and image file input/ouput helper functions. Each augmentation is a function that expects a list of (image, label) tuples, and returns the original tuples as well as all augmented versions of each (image, label) tuple in a larger list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "editable": true,
        "id": "ffYKzEDIz225",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments\n",
        "def brightnessAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(1.05, 1.05), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        bright_img = transform(image=image)[\"image\"]\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(0.95, 0.95), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        dark_img = transform(image=image)[\"image\"]\n",
        "        out.append(bright_img)\n",
        "        out.append(dark_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering\n",
        "def blurAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        ksize = (10, 10) # lower to lower blur\n",
        "        blurred_img = cv2.blur(image, ksize)\n",
        "        out.append(blurred_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure\n",
        "def contrastAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.1, 0.1), saturation=0, hue=0, always_apply=True) ])\n",
        "        decontrasted_img = transform(image=image)[\"image\"]\n",
        "        out.append(decontrasted_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds\n",
        "def noiseAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ISONoise(color_shift=(0.01, 0.01), intensity=(0.8, 0.8), always_apply=True) ])\n",
        "        noisy_img = transform(image=image)[\"image\"]\n",
        "        out.append(noisy_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images\n",
        "def resolutionAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        #interpolation=A.augmentations.transforms.Interpolation(downscale=cv2.INTER_NEAREST, upscale=cv2.INTER_NEAREST)\n",
        "        transform = A.Compose([ A.augmentations.transforms.Downscale(scale_min=0.25, scale_max=0.25, always_apply=True) ])\n",
        "        low_res_img = transform(image=image)[\"image\"]\n",
        "        out.append(low_res_img)\n",
        "    return out\n",
        "\n",
        "#increase intensity of blues in given image\n",
        "def make_bluer(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_b = np.uint16(img_b)\n",
        "    img_b += color_shift_intensity\n",
        "    np.clip(img_b, 0, 255, out=img_b)\n",
        "    img_b = np.uint8(img_b)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#increase intensity of greens in given image\n",
        "def make_greener(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_g = np.uint16(img_g)\n",
        "    img_g += color_shift_intensity\n",
        "    np.clip(img_g, 0, 255, out=img_g)\n",
        "    img_g = np.uint8(img_g)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation\n",
        "def colorAugment(images):\n",
        "    out = []\n",
        "    color_shift_intensity = int(255*0.1)\n",
        "    for image in images:\n",
        "        blue_img = make_bluer(image, color_shift_intensity)\n",
        "        green_img = make_greener(image, color_shift_intensity)\n",
        "        out.append(blue_img)\n",
        "        out.append(green_img)\n",
        "    return out\n",
        "\n",
        "#remove all files/folders in folder\n",
        "def clearFolder(folder):\n",
        "    #get all directory/filenames in folder\n",
        "    for filename in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                #delete all files\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                #recursively delete everything in sub-folders\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "#output given samples to given folder so that each image has corresponding label with same filename in /images and /labels subfolders respectively\n",
        "def sendToFolders(samples, output_folder):\n",
        "    #remove all files/folders in output folders\n",
        "    clearFolder(output_folder + \"/images\")\n",
        "    clearFolder(output_folder + \"/labels\")\n",
        "    instance_count = 0 #keep track of instance count for filename\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        #write image to file in /images\n",
        "        cv2.imwrite(output_folder + '/images/img' + str(instance_count) + '.png', image)\n",
        "        #write label to file in /labels\n",
        "        with open(output_folder + '/labels/img' + str(instance_count) + '.txt', 'w+') as f:\n",
        "            #each box gets its own line\n",
        "            for box in label:\n",
        "                f.write(box)\n",
        "        instance_count += 1\n",
        "\n",
        "#given array of image/label arrays, and an integer of how to split the data, returns the dataset split accordingly\n",
        "def splitData(samples, splits):\n",
        "    #for now we just shuffle the data to hopefully get a similar sample size\n",
        "    # of images for every class in the train, test and val splits\n",
        "    #ideally in the future we should split by class and then combine together to make sure the datasets are balanced\n",
        "\n",
        "    #shuffle data\n",
        "    random.shuffle(samples)\n",
        "    #get indices for split\n",
        "    splits = [int(len(samples)*s) for s in splits]\n",
        "    #return split data\n",
        "    return samples[:splits[0]], samples[splits[0]:splits[0]+splits[1]], samples[splits[0]+splits[1]:]\n",
        "\n",
        "#given a single image and augmentation function, displays the image before and images after augmentation\n",
        "def visualizeAugmentation(img, aug):\n",
        "    #show original image\n",
        "    cv2.imshow('og', img)\n",
        "    cv2.waitKey(0)\n",
        "    #show all augmented images\n",
        "    for augmented in aug([(img, \"\")])[1:]:\n",
        "        cv2.imshow('augmented',augmented[0])\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "#given source dataset folder, loads all images and labels into arrays\n",
        "def loadInputData(source_folder):\n",
        "    samples = []\n",
        "    #get all filenames in the /images subfolder of given source_folder\n",
        "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
        "    for img_filename in img_filenames:\n",
        "        #load image at that filename\n",
        "        img = cv2.imread(source_folder + '/images/' + img_filename)\n",
        "        #got label filename corresponding to the image\n",
        "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
        "        #load in the label file contents\n",
        "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
        "            #build array of bounding boxes (each line its own element)\n",
        "            bounding_boxes = []\n",
        "            for line in f.read().split(\"\\n\"):\n",
        "                bounding_boxes.append(line)\n",
        "        #add image and label to sample set\n",
        "        samples.append( (img, bounding_boxes) )\n",
        "    del img_filenames\n",
        "    return samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yHQqr4W4XxPU"
      },
      "outputs": [],
      "source": [
        "def get_file_names(source_folder):\n",
        "    label_filenames = []\n",
        "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
        "    for img_filename in img_filenames:\n",
        "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
        "\n",
        "    return np.array(img_filenames), np.array(label_filenames)\n",
        "\n",
        "def split_file_names(images,labels,splits):\n",
        "    perm = np.random.permutation(len(images))\n",
        "    images = images[perm]\n",
        "    labels = labels[perm]\n",
        "    splits = [int(len(images)*s) for s in splits]\n",
        "    train_images = images[:splits[0]]\n",
        "    train_labels = labels[:splits[0]]\n",
        "    val_images = images[splits[0]: splits[0] + splits[1]]\n",
        "    val_labels = labels[splits[0]: splits[0] + splits[1]]\n",
        "    test_images = images[splits[0] + splits[1]:]\n",
        "    test_labels = labels[splits[0] + splits[1]:]\n",
        "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
        "\n",
        "def get_augs(img_filename,source_folder):\n",
        "    img = cv2.imread(source_folder + '/images/' + img_filename)\n",
        "    prob = 0.5\n",
        "    augs = [img]\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + colorAugment([img])\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + brightnessAugment(augs)\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + contrastAugment(augs)\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + blurAugment(augs)\n",
        "    return augs\n",
        "\n",
        "def do_augs_and_export(img_filenames,label_filenames,source_folder,output_folder):\n",
        "    name_num = 1\n",
        "    for (img_filename,label_filename) in zip(img_filenames,label_filenames):\n",
        "        augs = get_augs(img_filename,source_folder)\n",
        "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
        "            #build array of bounding boxes (each line its own element)\n",
        "            bounding_boxes = f.read()\n",
        "        for aug in augs:\n",
        "            cv2.imwrite(output_folder + '/images/img' + str(name_num) + '.png', aug)\n",
        "            with open(output_folder + '/labels/img' + str(name_num) + '.txt',\"w+\") as f:\n",
        "                f.write(bounding_boxes)\n",
        "            name_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get data from roboflow: Go to Versions > Export Dataset > Choose Format: YOLOv5 > Click \"show download code\" > Continue > Copy-paste the download code below\n",
        "#Change name of folder --> write code to do this after\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Id86zM4cvFb8WmWN0N1N\")\n",
        "project = rf.workspace(\"auv2024\").project(\"front-cam-real\")\n",
        "dataset = project.version(2).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8tP5PdblZW1U",
        "outputId": "a31a1673-5a20-4341-d0f3-9c4ffffdcc1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.11-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.16.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.45.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "Installing collected packages: python-magic, python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.8.1.78\n",
            "    Uninstalling opencv-python-headless-4.8.1.78:\n",
            "      Successfully uninstalled opencv-python-headless-4.8.1.78\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.11 supervision-0.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cv2",
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Front-cam-real-2 to yolov5pytorch:: 100%|██████████| 74225/74225 [00:01<00:00, 51090.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Front-cam-real-2 in yolov5pytorch:: 100%|██████████| 1824/1824 [00:00<00:00, 4095.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Do the bash stuff to rename/move the images\n",
        "!rm -r sample_data\n",
        "#rename 'old-name-dir' new-name-dir old-name-dir --> RENAME TRAIN\n",
        "!mv /content/Front-cam-real-2/train/ /content/data/raw\n",
        "!rm -r Front-cam-real-1\n",
        "#Check if we need the yaml file in Front-cam-real-1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcVUzx2bsY67",
        "outputId": "876105c2-a480-45ef-ab43-c575bddfa93d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'Front-cam-real-1': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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))"
      ],
      "metadata": {
        "id": "UALJIL396R8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6f4fmIgXxPU"
      },
      "outputs": [],
      "source": [
        "train_test_val_split = (0.7, 0.2, 0.1)\n",
        "out_folder = \"data/augmented\"\n",
        "in_folder = \"data/raw\"\n",
        "\n",
        "img_names, label_names = get_file_names(in_folder)\n",
        "train_images, train_labels, val_images, val_labels, test_images, test_labels = split_file_names(img_names,label_names,train_test_val_split)\n",
        "do_augs_and_export(train_images,train_labels,in_folder,out_folder + \"/train\")\n",
        "do_augs_and_export(val_images,val_labels,in_folder,out_folder + \"/val\")\n",
        "do_augs_and_export(test_images,test_labels,in_folder,out_folder + \"/test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "NY5fTW4G02T0",
        "tags": []
      },
      "source": [
        "Load in all files from /raw folder, pass list of images sequentially through each augmentation function, then output final images to /augmented folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "uByRW0J20W8e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# train_test_val_split = (0.7, 0.2, 0.1)\n",
        "# out_folder = \"data/augmented\"\n",
        "# in_folder = \"data/raw\"\n",
        "\n",
        "# print(\"Loading data...\")\n",
        "# data = loadInputData(in_folder)\n",
        "\n",
        "#FOR TESTING uncomment to visualize individual augmentations\n",
        "#visualizeAugmentation(data[0][0], colorAugment)\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoHfG0GZXxPV"
      },
      "outputs": [],
      "source": [
        "# def do_all_augs(stuff):\n",
        "#     stuff = colorAugment(stuff)\n",
        "#     stuff = brightnessAugment(stuff)\n",
        "#     sutff = contrastAugment(stuff)\n",
        "#     return blurAugment(stuff)\n",
        "\n",
        "# train, test, val = splitData(data, train_test_val_split)\n",
        "\n",
        "# # print(\"Augmenting color...\")\n",
        "# data = colorAugment(data) # times 3\n",
        "# print(\"Augmenting brightness...\")\n",
        "# data = brightnessAugment(data) # times 3\n",
        "# print(\"Augmenting contrast...\")\n",
        "# data = contrastAugment(data) # times 2\n",
        "# #print(\"Augmenting blur...\")\n",
        "# #data = blurAugment(data) # times 2\n",
        "# print(\"Splitting data...\")\n",
        "\n",
        "# train = do_all_augs(train)\n",
        "# test = do_all_augs(test)\n",
        "# val = do_all_augs(val)\n",
        "\n",
        "# print(\"Exporting training data...\")\n",
        "# sendToFolders(train, out_folder + \"/train\")\n",
        "# print(\"Exporting test data...\")\n",
        "# sendToFolders(test, out_folder + \"/test\")\n",
        "# print(\"Exporting val data...\")\n",
        "# sendToFolders(val, out_folder + \"/val\")\n",
        "# print(\"Done. Final number of samples: \" + str(len(data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "Ha6R_QiX1mrs",
        "tags": []
      },
      "source": [
        "# Train YOLO model with augmented data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZBXU0OD7l9b",
        "outputId": "8950f488-1e4f-4ce0-9214-f4d546aaa0ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "#Ensure this prints true and a number > 0, if not make sure you set hardware accelerator to GPU in Edit > Notebook Settings > Hardware Accelerator\n",
        "# !rm -r runs/detect/train*\n",
        "!mkdir runs\n",
        "!mkdir runs/detect\n",
        "!mkdir runs/detect/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "w1a82eTY1rFt",
        "outputId": "e1d9f117-3797-456c-d224-aa83796bc238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/60      2.29G      1.204     0.9841      1.402         11        640: 100%|██████████| 375/375 [06:13<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:51<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1707       7427      0.953      0.892      0.928      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/60      2.23G      1.219      1.044      1.397        128        640:   1%|▏         | 5/375 [00:03<04:23,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-abff7e2768d4>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mepoch_increments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# while True:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_increments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflipud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfliplr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperspective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmosaic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmixup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'detect'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#shutil.copyfile(\"runs/detect/train\" + str(i) + \"/weights/best.pt\", \"/content/drive/My Drive/AUV_model_\" + str(i) + \".pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#UNCOMMENT TO START FROM SCRATCH\n",
        "torch.cuda.empty_cache()\n",
        "#model = YOLO(\"yolov8n.pt\")  # load a pretrained model\n",
        "#model = YOLO(\"runs/detect/train11/weights/last.pt\")\n",
        "# CONTINUE TRAINING\n",
        "model = YOLO(\"/best (6).pt\") #load a previous model in case training interrupts\n",
        "\n",
        "# Train the model in increments\n",
        "epoch_increments = 60\n",
        "# while True:\n",
        "model.train(data=\"data.yaml\", epochs=epoch_increments, device=0, batch=16, degrees=360, flipud=0.5, fliplr=0.5, perspective=0.001, translate=0.1, scale=0.3,mosaic=0.5,mixup=0.5, pretrained=True, task='detect')  # train the model\n",
        "model.val()\n",
        "#shutil.copyfile(\"runs/detect/train\" + str(i) + \"/weights/best.pt\", \"/content/drive/My Drive/AUV_model_\" + str(i) + \".pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcV3fZqHXxPW"
      },
      "outputs": [],
      "source": [
        "def visualizeBbox(img, bbox, class_name, thickness=2, fontSize=0.5):\n",
        "    #get xmin, xmax, ymin, ymax from bbox\n",
        "    BOX_COLOR=(0,255,0)\n",
        "    TEXT_COLOR = (0,0,0)\n",
        "    x_center, y_center, w, h = bbox\n",
        "    x_min = x_center - w/2\n",
        "    y_min = y_center - h/2\n",
        "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
        "    #draw bounding box on image\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=BOX_COLOR, thickness=thickness)\n",
        "    #get size of class name text\n",
        "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, fontSize, 1)\n",
        "    #draw box around class name label on image\n",
        "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
        "    #put class name text in the box we drew\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        text=class_name,\n",
        "        org=(x_min, y_min - int(0.3 * text_height)),\n",
        "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=fontSize,\n",
        "        color=TEXT_COLOR,\n",
        "        lineType=cv2.LINE_AA,\n",
        "    )\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Tpx-d_3Mj5"
      },
      "source": [
        "# Predict on image with model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdXmFvGW3Q8J",
        "outputId": "caff4afd-cec7-4bdf-9c34-085cecffd61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 1 Earth Symbol, 1 Octagon Table, 101.6ms\n",
            "Speed: 3.7ms preprocess, 101.6ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([5., 2.], device='cuda:0')\n",
            "conf: tensor([0.8556, 0.3383], device='cuda:0')\n",
            "data: tensor([[1.8616e+02, 0.0000e+00, 8.5335e+02, 5.4959e+02, 8.5564e-01, 5.0000e+00],\n",
            "        [4.5889e+01, 8.6485e+01, 6.0198e+02, 4.4967e+02, 3.3832e-01, 2.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (561, 994)\n",
            "shape: torch.Size([2, 6])\n",
            "xywh: tensor([[519.7531, 274.7956, 667.1948, 549.5912],\n",
            "        [323.9359, 268.0766, 556.0939, 363.1833]], device='cuda:0')\n",
            "xywhn: tensor([[0.5229, 0.4898, 0.6712, 0.9797],\n",
            "        [0.3259, 0.4779, 0.5595, 0.6474]], device='cuda:0')\n",
            "xyxy: tensor([[186.1556,   0.0000, 853.3505, 549.5912],\n",
            "        [ 45.8889,  86.4849, 601.9828, 449.6682]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1873, 0.0000, 0.8585, 0.9797],\n",
            "        [0.0462, 0.1542, 0.6056, 0.8015]], device='cuda:0')\n",
            "\n",
            "prediction:[tensor([519.7531, 274.7956, 667.1948, 549.5912], device='cuda:0'), tensor([323.9359, 268.0766, 556.0939, 363.1833], device='cuda:0')]\n",
            "\n",
            "prediction:[tensor(0.8556, device='cuda:0'), tensor(0.3383, device='cuda:0')]\n",
            "\n",
            "prediction:[tensor(5., device='cuda:0'), tensor(2., device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "img_path = \"data/augmented/test/images/img105.png\"\n",
        "img = cv2.imread(img_path)\n",
        "# Load a model\n",
        "model = YOLO(\"runs/detect/train3/weights/best.pt\")  # load a model\n",
        "# Use the model\n",
        "pred = model(img)\n",
        "for results in pred:\n",
        "    box = results.boxes\n",
        "    print(box)\n",
        "    print(\"\\nprediction:\" + str(list(box.xywh)))\n",
        "    print(\"\\nprediction:\" + str(list(box.conf)))\n",
        "    print(\"\\nprediction:\" + str(list(box.cls)))\n",
        "\n",
        "points = box.xywh.tolist()[0]\n",
        "boxed = visualizeBbox(img,points,\"gate\")\n",
        "cv2.imwrite(\"test.png\",boxed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaXSVf1PXxPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "98bd2cbd-2c2a-4ab3-d08b-02690475bbde"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1c3cac462029>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mcustom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imgsz'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imgsz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'verbose'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# method defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcustom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mode'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'export'\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# highest priority args on the right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'IterableSimpleNamespace' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "model.export()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MAQ76bSTy48-",
        "COpq9wZczt1G"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}